{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DJDhoNBYnOh"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFHyIIFNZNER"
      },
      "source": [
        "with open('./tokenizer.pickle', 'rb') as token:\n",
        "  tokenizer = pickle.load(token)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-GGKp4tZqb-"
      },
      "source": [
        "def Encoding(text):\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "  paded = pad_sequences(\n",
        "      sequence,\n",
        "      padding = 'pre',\n",
        "      truncating = 'post',\n",
        "      maxlen = 125\n",
        "  )\n",
        "  return paded"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TriJzgw-aLat"
      },
      "source": [
        "def TextProcessing(text_list):\n",
        "  sequences_list = []\n",
        "  for text in text_list:\n",
        "    sequence = Encoding(text)\n",
        "    # print(sequence[0])\n",
        "    # print()\n",
        "    sequences_list.append(sequence[0])\n",
        "  sequences_list = np.array(sequences_list)\n",
        "  return sequences_list"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsoEXS6LaVqw"
      },
      "source": [
        "sentences = [\n",
        "    \"Pemerintah buat kebijakan odong odong banget\",\n",
        "    \"pemerintah buat kebijakan kok asal banget ya kayanya\",\n",
        "    \"bukit algoritma tu kek ngayal banget, kurang masuk akal\",\n",
        "    \"pemerintah udah kerja bagus sejauh ini\",\n",
        "    \"Pak jokowi udah kerja bagus selama 2 periode ini\",\n",
        "    \"uu ciptaker ini bener bener buat sengsara buruh doang\",\n",
        "    \"udah tau vaksin haram, masih aja vaksin\",\n",
        "    \"buat kebijakan samasekali kaga nyambung sama situasi #tolakkebijakanini\",\n",
        "    \"kebijakan sampah, gajelas, kebijakan tolol\",\n",
        "    \"kebijakan yang seperti ini sih bener bener dibutuhin rakyat #dukungkebijakanini\",\n",
        "    \"dasar goblok\"\n",
        "]"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzBxP2NyankF"
      },
      "source": [
        "sequences_result = TextProcessing(sentences)"
      ],
      "execution_count": 96,
      "outputs": []
    },
  ]
}
